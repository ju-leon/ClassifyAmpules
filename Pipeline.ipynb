{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Izy4Q5iGFx1S"
   },
   "source": [
    "# Classify Ampules\n",
    "\n",
    "\n",
    "## Getting started\n",
    "\n",
    "Erstmal müssen wir unser Repository in unsere Colab Instanz laden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "1EhG5b5fa0ti",
    "outputId": "6e6c0f52-7e3b-4769-c7af-090b5dcc6083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ClassifyAmpules'...\n",
      "remote: Enumerating objects: 137, done.\u001b[K\n",
      "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
      "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
      "remote: Total 137 (delta 79), reused 92 (delta 40), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (137/137), 3.50 MiB | 3.20 MiB/s, done.\n",
      "Resolving deltas: 100% (79/79), done.\n",
      "/content/ClassifyAmpules\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ju-leon/ClassifyAmpules.git\n",
    "%cd ClassifyAmpules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bU1slAL5Fx1Y"
   },
   "source": [
    "### Google Drive\n",
    "\n",
    "Wir verwenden **Google Drive** um Daten zu laden und zu speichern.\n",
    "Zum Einbinden von Google Drive dem Link unten folgen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "CGNM2C0oc5Kr",
    "outputId": "a463ccd0-9c09-4076-e312-1b1a3e0b229c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSbYSqemEBtM"
   },
   "source": [
    "### Updating\n",
    "\n",
    "Um Änderungen in unserem Repositiory sichbar zu machen muss es neu geladen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4qZnM1PvD-gI"
   },
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7GxMmEPXDv4f"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Hier setzen wir unser Dateisystem auf.\n",
    "\n",
    "**Source Path:** Pfad zu den Rohdaten\n",
    "\n",
    "**Cache Path:** Pfad in ein leeren Ordner. Hier werden Bilder nach der ersten Preprocessing Schritt gespeichert.\n",
    "\n",
    "**Out Path:** Pfad in ein leeren Ordner. Hier werden die fertig verarbeiteten Bilder gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCa2J4tTbggc"
   },
   "outputs": [],
   "source": [
    "source_path = \"/content/drive/My Drive/Hackaton/PIM_Dataset\"\n",
    "cache_path = \"/content/drive/My Drive/Hackaton/PIM_combi\"\n",
    "out_path =  \"/content/drive/My Drive/Hackaton/combined\"\n",
    "\n",
    "source_path_good = \"'\" + source_path + \"/good_piece/\" + \"'\"\n",
    "source_path_bad = \"'\" + source_path + \"/bad_piece\" + \"'\"\n",
    "\n",
    "cache_path_good = \"'\" + cache_path + \"/good_piece/\" + \"'\"\n",
    "cache_path_bad = \"'\" + cache_path + \"/bad_piece/\" + \"'\"\n",
    "\n",
    "out_path_good = \"'\" + out_path + \"/good_piece/\" + \"'\"\n",
    "out_path_bad = \"'\" + out_path + \"/bad_piece/\" + \"'\"\n",
    "out_path = \"'\" + out_path + \"'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CiftkKNmFx1j"
   },
   "source": [
    "Falls die (leeren) Ordner noch nicht existieren erstellen wir sie..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aK23KqcbFx1j"
   },
   "outputs": [],
   "source": [
    "%mkdir -p $cache_path_good $cache_path_bad $out_path_good $out_path_bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pd3kU_Ola0tn"
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "![Raw Data](https://github.com/ju-leon/ClassifyAmpules/blob/master/docs/metal226_3.bmp?raw=1)\n",
    "\n",
    "Als erstes müssen wir die Datenmenge reduzieren.\n",
    "\n",
    "Wir verwenden einen **min Filter** der Größe 9 bevor wir runter skalieren. \n",
    "Dadurch werden Abweichungen von dem Hintergrund wie Metallteile hervorgehoben und vergrößert. Das verhindert, das diese Merkmale beim runterskalieren verloren gehen.\n",
    "Hier sieht man, dass das Metallstück rechts unten deutlich größer erscheint und somit beim runterskalieren noch deutlich besser sichtbar ist.\n",
    "\n",
    "\n",
    "![Raw Data](https://github.com/ju-leon/ClassifyAmpules/blob/master/docs/after_preprocess.png?raw=1)\n",
    "\n",
    "Danach scheiden wir den wichtigen Bildbereich aus.\n",
    "Mit mehr Zeit könnte man dieses Ausschneiden intelligent machen, das also immer genau die Ampullen ausgeschnitten werden.\n",
    "Das würde die Datenmenge deutlich reduzieren, die Variation zwischen den Bildern minimieren, und damit höchstwahrscheinlich das Klassifikationsergebniss um ein Vielfaches verbessern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YU5UtGG2a0to"
   },
   "outputs": [],
   "source": [
    "!python3 preprocess.py $source_path_good $cache_path_good\n",
    "!python3 preprocess.py $source_path_bad $cache_path_bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J3_VjgOTa0ts"
   },
   "source": [
    "# Combining\n",
    "\n",
    "Für jedes Sample werden 3 Bilder angegeben. \n",
    "Um ein Overfitting zu vermeiden, müssen diese Bilder kombiniert werden, sonst könnte das Netz allein anhand der Ausrichtung der Ampullen erkennen ob sie Verunreinigt sind. Das würde die Metriken bei Training nutzlos machen.\n",
    "\n",
    "Deshab legen wir alle 3 Bilder übereinander. Wir nehmen für jedes Pxxel das mit dem dunkelsten Wert.\n",
    "Dadurch bleiben wichtige Merkmale wie Metallstücke erhalten, doppelte Info wie Ränder verschwinden.\n",
    "\n",
    "![Raw Data](https://github.com/ju-leon/ClassifyAmpules/blob/master/docs/metal226.png?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hb-94e0na0tt"
   },
   "outputs": [],
   "source": [
    "!python3 combine.py $cache_path_good $out_path_good\n",
    "!python3 combine.py $cache_path_bad $out_path_bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwsoNCHrOsCv"
   },
   "source": [
    "# Filter by bad piece\n",
    "\n",
    "Hier werden die schlechten Bilder in die einzelnen Klassen aufgeteilt. Das wird nur dann benötigt, wenn man auch noch klassifizieren möchte welcher Fehler auftritt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zEPnV1ZBLVGJ"
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "import os\n",
    "path = \"/content/drive/My Drive/Hackaton/combined/good_piece/\"\n",
    "\n",
    "valid_images = \".png\"\n",
    "for f in os.listdir(path):\n",
    "    if f.endswith(valid_images):\n",
    "        copyfile(path + f, \"/content/drive/My Drive/Hackaton/all_classes/good/\" + f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47W-zxewa0tw"
   },
   "source": [
    "# Training\n",
    "\n",
    "Jetzt können wir das Netz trainieren. \n",
    "\n",
    "\n",
    "Wir verwenden Tensorflow und die high-level API Keras zum Trainieren eines neuronalen Netzes.\n",
    "Bei unserer Architektur, setzen wir angelehnt an Imagenet (vgl. https://arxiv.org/abs/1409.0575)\n",
    "auf ein CNN (Convolutional Neural Network) das mehrere Convolutional Blocks (Convolutional Layer + Max Pooling Layer) beinhaltet, die mit Relu aktiviert werden. Darauf folgt ein Dropout und darauf 3 Fully Connected Layer um zu klassifizieren. Der finale Output wird durch einen Softmax-Layer erzeugt. \n",
    "\n",
    "Dieser erzeugt Pseudowahrscheinlichkeiten für die Zugehörigkeit eines gebenen Sample zur jeweiligen Klasse (Good Piece, Bad Piece).\n",
    "Diese Architektur hat sich zum Klassifizieren von Bildern bewährt, da Features durch Convolutional Layer gelernt werden und dann durch die Fully Connected Layer klassifiziert werden können.\n",
    "\n",
    "Wir haben auch Tests mit einem Netzwerk das auf metal, gasket, charred, good klassifiziert gemacht. Dabei haben wir ein accurcy von 75% erreicht, wobei die meisten Fehler innerhalb der \"bad-Klassen\" erfolgt sind. die Fehler wären also nicht besonders schlimm, da nur der grund für die Ablehnung falsch klassifiziert wurde, aber nur selten fälschlicherweise eine defekte Charge als gut klassifiziert wurde. \n",
    "Dennoch ist insgesamt die Fehlerhäufigkeit höher, was auch an der sehr geringen Datenmenge pro Klasse liegen könnte wenn man die \"bad_piece\" Klasse noch weiter in 3 Unterklassen aufteilt.\n",
    "\n",
    "\n",
    "Unsere Daten werden geshuffelt und in Test und Validierungsdaten aufgeteilt (Verhältnis 70%:30%).\n",
    "Wir verwenden ADAM (vgl. https://arxiv.org/abs/1412.6980) als Optimierungsalgorithmus und validieren die Optimierung nach jeder Trainingsepoche mit unserem Validierungsdatensatz. Verbessert sich die Genauigkeit des Netzes wird dieses gespeichert. Am Ende des Training werden mit dem besten Netz auf dem Validierungsdatensatz die Confusion Matrix und Metriken wie f1-score, precision, ... erzeugt.\n",
    "\n",
    "## Anmerkung zu Hyperparameteroptimierung\n",
    "Parameter wie Lernrate, Anzahl der Schichten, Größe der Schichten, Größe der Convultional Filter usw. können durch Systematische Ansätze der Hyperparameteroptimierung (wie z.B Neural Architecture Search) immer weiter Optimiert werden. Solche Ansätze sprengen leider den Zeitlichen Rahmen eines Hackathons, führen aber, auf Grundlage der von uns geschaffenen Architektur, zu exzellenten Ergebnissen. Die weiter Optimierung wäre für den Produktiveinsatz wünschenswert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ijLNnPtha0tw",
    "outputId": "d71baa2a-082f-4eb2-8ac9-912d3649a7e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2020-07-03 14:37:20.562516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "Found 892 images belonging to 2 classes.\n",
      "Found 382 images belonging to 2 classes.\n",
      "2020-07-03 14:37:23.272350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-07-03 14:37:23.315794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-03 14:37:23.316575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2020-07-03 14:37:23.316628: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-03 14:37:23.525624: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-07-03 14:37:23.676684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-07-03 14:37:23.696573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-07-03 14:37:23.978682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-07-03 14:37:23.995876: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-07-03 14:37:24.508882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-07-03 14:37:24.509135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-03 14:37:24.510005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-03 14:37:24.510739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2020-07-03 14:37:24.563150: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2200000000 Hz\n",
      "2020-07-03 14:37:24.563425: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2ccd480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-07-03 14:37:24.563472: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-07-03 14:37:24.655108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-03 14:37:24.655980: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f03500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-07-03 14:37:24.656014: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2020-07-03 14:37:24.656795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-03 14:37:24.657494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2020-07-03 14:37:24.657553: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-03 14:37:24.657605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-07-03 14:37:24.657651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-07-03 14:37:24.657693: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-07-03 14:37:24.657739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-07-03 14:37:24.657802: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-07-03 14:37:24.657847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-07-03 14:37:24.657938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-03 14:37:24.658812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-03 14:37:24.659645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2020-07-03 14:37:24.662460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-03 14:37:30.260050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-07-03 14:37:30.260112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2020-07-03 14:37:30.260132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2020-07-03 14:37:30.263432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-03 14:37:30.264283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-03 14:37:30.265085: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2020-07-03 14:37:30.265176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10634 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "2020-07-03 14:37:30.550416: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\n",
      "2020-07-03 14:37:30.551451: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1363] Profiler found 1 GPUs\n",
      "2020-07-03 14:37:30.596316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1\n",
      "2020-07-03 14:37:30.756778: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1479] CUPTI activity buffer flushed\n",
      "Epoch 1/1\n",
      "2020-07-03 14:38:00.666305: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-07-03 14:38:02.059454: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      " 1/27 [>.............................] - ETA: 17:17 - loss: 0.6892 - accuracy: 0.59382020-07-03 14:38:11.839435: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\n",
      " 2/27 [=>............................] - ETA: 11:44 - loss: 0.7256 - accuracy: 0.43752020-07-03 14:38:28.309539: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1479] CUPTI activity buffer flushed\n",
      "2020-07-03 14:38:28.311101: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:216]  GpuTracer has collected 787 callback api events and 787 activity events.\n",
      "2020-07-03 14:38:28.339941: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: logs/1593787050.5503173/train/plugins/profile/2020_07_03_14_38_28\n",
      "2020-07-03 14:38:28.354188: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to logs/1593787050.5503173/train/plugins/profile/2020_07_03_14_38_28/c9a2dd0c8dfd.trace.json.gz\n",
      "2020-07-03 14:38:28.362664: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0.271 ms\n",
      "\n",
      "2020-07-03 14:38:28.365428: I tensorflow/python/profiler/internal/profiler_wrapper.cc:87] Creating directory: logs/1593787050.5503173/train/plugins/profile/2020_07_03_14_38_28Dumped tool data for overview_page.pb to logs/1593787050.5503173/train/plugins/profile/2020_07_03_14_38_28/c9a2dd0c8dfd.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/1593787050.5503173/train/plugins/profile/2020_07_03_14_38_28/c9a2dd0c8dfd.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/1593787050.5503173/train/plugins/profile/2020_07_03_14_38_28/c9a2dd0c8dfd.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/1593787050.5503173/train/plugins/profile/2020_07_03_14_38_28/c9a2dd0c8dfd.kernel_stats.pb\n",
      "\n",
      " 7/27 [======>.......................] - ETA: 8:40 - loss: 0.7067 - accuracy: 0.4866"
     ]
    }
   ],
   "source": [
    "!python3 train.py $out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ergebniss\n",
    "\n",
    "Nach dem Training über 100 Epochen hat unser Model folgende Ergebnisse\n",
    "\n",
    "![Raw Data](docs/result.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web UI\n",
    "\n",
    "\n",
    "Zum Einfachen testen haben wir zudem eine Web UI begonnen, die wie folgt aussieht:\n",
    "\n",
    "\n",
    "![Raw Data](docs/edit.gif)\n",
    "![Raw Data](docs/webui.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Pipeline.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
