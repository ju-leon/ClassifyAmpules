{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Pipeline.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQlzPB0eFMP-",
        "colab_type": "text"
      },
      "source": [
        "# Classification of Ampules\n",
        "\n",
        "First, make sure to select **GPU** as runtime type under Runtime > Change Runtime Type\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAR_mQBbFJM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5b288f0e-fc94-42bc-bd8a-bd7de7b5fc88"
      },
      "source": [
        "!git clone https://github.com/ju-leon/ClassifyAmpules.git\n",
        "%cd ClassifyAmpules"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ClassifyAmpules' already exists and is not an empty directory.\n",
            "/content/ClassifyAmpules\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg7yfN4fFtmq",
        "colab_type": "text"
      },
      "source": [
        "Whenever you update your code remotely, just run the following command to refresh it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D_pPwvMFtOC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "72d4d8d6-74e2-4a48-ee6b-1dcf2c777a72"
      },
      "source": [
        "!git fetch --all\n",
        "!git reset --hard origin/master "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching origin\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 5 (delta 3), reused 5 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), done.\n",
            "From https://github.com/ju-leon/ClassifyAmpules\n",
            "   0a9fc55..77b00da  master     -> origin/master\n",
            "HEAD is now at 77b00da Fix arguments\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLQnuyTkFeB5",
        "colab_type": "text"
      },
      "source": [
        "Next, we need to connect to our **Google Drive** to load and store our data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zstrdbvOFm6u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "cd8974fa-b416-4918-943b-77f1aff26d07"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1ohlKfPFJM_",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "First, we need to scale down our data.\n",
        "\n",
        "Repace the path with the path where your data is stored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKXREDagHP9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Change these paths\n",
        "in_path = \"/content/drive/My Drive/Hackaton/PIM_Dataset\"\n",
        "cache_path = \"/content/drive/My Drive/Hackaton/cache\"\n",
        "out_path = \"/content/drive/My Drive/Hackaton/out\"\n",
        "\n",
        "\n",
        "#Do not touch\n",
        "in_path_good = \"'\" + in_path + \"/good_piece/\" + \"'\"\n",
        "in_path_bad = \"'\" + in_path + \"/bad_piece/\" + \"'\"\n",
        "\n",
        "cache_path_good = \"'\" + cache_path + \"/good_piece/\" + \"'\"\n",
        "cache_path_bad = \"'\" + cache_path + \"/bad_piece/\" + \"'\"\n",
        "\n",
        "out_path = \"'\" + out_path + \"/\" + \"'\"\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odupyJgoFJM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python preprocess.py $in_path_good $cache_path_good\n",
        "!python preprocess.py $in_path_bad $cache_path_bad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhCwm15UFJNE",
        "colab_type": "text"
      },
      "source": [
        "# Combining\n",
        "\n",
        "Now we combine 3 images into one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV5byFi_FJNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 combine.py $cache_path_good $out_path_good\n",
        "!python3 combine.py $cache_path_bad $out_path_bad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXb6gRFjFJNI",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHvyCTf4FJNI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74ec1b6d-bd6c-4a04-a23b-6b5fe4321467"
      },
      "source": [
        "!python3 train.py $out_path"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "2020-07-02 20:27:01.730033: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Found 7 images belonging to 2 classes.\n",
            "Found 2 images belonging to 2 classes.\n",
            "(100, 100, 3)\n",
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n",
            "2020-07-02 20:27:04.191033: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-02 20:27:04.214650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-02 20:27:04.215301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P4 computeCapability: 6.1\n",
            "coreClock: 1.1135GHz coreCount: 20 deviceMemorySize: 7.43GiB deviceMemoryBandwidth: 178.99GiB/s\n",
            "2020-07-02 20:27:04.215346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-02 20:27:04.217428: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-02 20:27:04.219222: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-02 20:27:04.219591: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-02 20:27:04.221745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-02 20:27:04.222716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-02 20:27:04.226761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-02 20:27:04.226874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-02 20:27:04.227490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-02 20:27:04.228145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-07-02 20:27:04.228427: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2020-07-02 20:27:04.233527: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2000150000 Hz\n",
            "2020-07-02 20:27:04.233724: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x272d480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-02 20:27:04.233752: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-07-02 20:27:04.329098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-02 20:27:04.329594: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x272dd40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-02 20:27:04.329625: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-07-02 20:27:04.329836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-02 20:27:04.330264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P4 computeCapability: 6.1\n",
            "coreClock: 1.1135GHz coreCount: 20 deviceMemorySize: 7.43GiB deviceMemoryBandwidth: 178.99GiB/s\n",
            "2020-07-02 20:27:04.330309: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-02 20:27:04.330349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-02 20:27:04.330371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-02 20:27:04.330391: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-02 20:27:04.330410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-02 20:27:04.330428: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-02 20:27:04.330448: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-02 20:27:04.330522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-02 20:27:04.330894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-02 20:27:04.331231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-07-02 20:27:04.331325: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-02 20:27:04.868658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-02 20:27:04.868718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
            "2020-07-02 20:27:04.868731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
            "2020-07-02 20:27:04.868982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-02 20:27:04.869449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-02 20:27:04.869819: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-07-02 20:27:04.869865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6966 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "2020-07-02 20:27:07.186131: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\n",
            "2020-07-02 20:27:07.186203: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1363] Profiler found 1 GPUs\n",
            "2020-07-02 20:27:07.187051: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1\n",
            "2020-07-02 20:27:07.318574: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1479] CUPTI activity buffer flushed\n",
            "Epoch 1/100\n",
            "2020-07-02 20:27:20.763392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-02 20:27:22.263374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            " 1/27 [>.............................] - ETA: 4:51 - loss: 1.7615 - accuracy: 0.14292020-07-02 20:27:27.212028: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.\n",
            " 2/27 [=>............................] - ETA: 2:21 - loss: 1.5377 - accuracy: 0.28572020-07-02 20:27:27.317764: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1479] CUPTI activity buffer flushed\n",
            "2020-07-02 20:27:27.318502: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:216]  GpuTracer has collected 3483 callback api events and 3483 activity events.\n",
            "2020-07-02 20:27:27.465207: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: logs/1593721627.1860642/train/plugins/profile/2020_07_02_20_27_27\n",
            "2020-07-02 20:27:27.542724: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to logs/1593721627.1860642/train/plugins/profile/2020_07_02_20_27_27/0e6aa0763dd8.trace.json.gz\n",
            "2020-07-02 20:27:27.587132: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 1.243 ms\n",
            "\n",
            "2020-07-02 20:27:27.608763: I tensorflow/python/profiler/internal/profiler_wrapper.cc:87] Creating directory: logs/1593721627.1860642/train/plugins/profile/2020_07_02_20_27_27Dumped tool data for overview_page.pb to logs/1593721627.1860642/train/plugins/profile/2020_07_02_20_27_27/0e6aa0763dd8.overview_page.pb\n",
            "Dumped tool data for input_pipeline.pb to logs/1593721627.1860642/train/plugins/profile/2020_07_02_20_27_27/0e6aa0763dd8.input_pipeline.pb\n",
            "Dumped tool data for tensorflow_stats.pb to logs/1593721627.1860642/train/plugins/profile/2020_07_02_20_27_27/0e6aa0763dd8.tensorflow_stats.pb\n",
            "Dumped tool data for kernel_stats.pb to logs/1593721627.1860642/train/plugins/profile/2020_07_02_20_27_27/0e6aa0763dd8.kernel_stats.pb\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.156970). Check your callbacks.\n",
            "  % (hook_name, delta_t_median), RuntimeWarning)\n",
            "27/27 [==============================] - 16s 583ms/step - loss: 0.1557 - accuracy: 0.9418 - val_loss: 3.5763e-07 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 1.00000, saving model to /content/drive/My Drive/Hackaton/nets/final.h5\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 3.3114e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 1.00000\n",
            "Epoch 3/100\n",
            "26/27 [===========================>..] - ETA: 0s - loss: 2.5807e-07 - accuracy: 1.0000Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 609, in get\n",
            "    future = self.queue.get(block=True)\n",
            "  File \"/usr/lib/python3.6/queue.py\", line 164, in get\n",
            "    self.not_empty.wait()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 295, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 619, in get\n",
            "    self.queue.task_done()\n",
            "  File \"/usr/lib/python3.6/queue.py\", line 68, in task_done\n",
            "    raise ValueError('task_done() called too many times')\n",
            "ValueError: task_done() called too many times\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 148, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 142, in main\n",
            "    callbacks=get_callbacks())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1732, in fit_generator\n",
            "    initial_epoch=initial_epoch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\", line 242, in fit_generator\n",
            "    workers=0)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1791, in evaluate_generator\n",
            "    verbose=verbose)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\", line 365, in evaluate_generator\n",
            "    generator_output = next(output_generator)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 624, in get\n",
            "    self.stop()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 501, in stop\n",
            "    self.run_thread.join(timeout)\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1056, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
            "    elif lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}